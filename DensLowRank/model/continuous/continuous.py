"""
Low-rank probability density function estimator for continuous distributions

Author : Laur√®ne David 
"""

import numpy as np
import math
from DensLowRank.model.discrete.discrete import * #import Discrete parent class of Continuous (doesn't work ??)
from scipy.stats import beta, randint #to sample continuous data


class Continuous(Discrete):

    #Class variables
    L = 1
    
    def __init__(self,alpha=0.1):
        """
        alpha : int/float, default = 0.1
        """
        if alpha < 0:
            raise ValueError(f"alpha should be positive")
        
        if type(alpha) not in (int,float):
            raise TypeError(f"alpha should be an int or float, not {type(alpha)}")
        
        self.alpha = alpha 
        self.funs = None
    


    def onedimensional_case(self,Z):
        # Algorithm 3 in the paper, not function available for user 
        ''' This function returns a density estimator for univariate continuous distributions.
        '''
        n = Z.shape[0]
        L = self.L

        r = np.min(Z[:int(n/2)])
        R = np.max(Z[:int(n/2)])

        if (R - r < n**(-1/3)*L**(-1/2)):
            return lambda x : 1/(R-r) if (x<=r and x>=R) else 0


        else:
            H = math.floor((R-r)*n**(1/3)*L**(1/2))**(-1)*(R-r)
            E = np.arange(-math.floor(r/H), math.ceil((1-r)/H-1))

            def f_1(x):
                s = 0
                N = np.zeros((len(E),))
            
                for i,j in enumerate(E):
                    a = r + j*H
                    b = r + (j+1)*H
                    N[i] = sum([1 for k in Z[int(n/2)+1:] if a <= k < b])
                
                    if (x>=j*H) and (x<=(j+1)*H):
                        s += N[i]
    
                return (1/H)*s
        

            return f_1

    

    def fit(self,X):
        """
        Compute a probability density function estimator for bivariate continuous distributions.


        Parameters :
        ------

        n : int 
        sample size 

        X : np.array of shape (n,2)
        a numpy array generated by a joint continuous distribution 
    
        alpha : float 
        a constant 


        Return :
        ------
        density_estimator(x) : python function 
        A density function estimator for bivariate distributions 
        with input x as 2d np.array
    
    
        """

        n = X.shape[0]
        L = self.L

        # Condition 1
        r_1 = np.min(X[:int(n/2),0])
        R_1 = np.max(X[:int(n/2),0])

        if R_1 - r_1 < n**(1/3)*L**(-1/2):
            g = self.onedimensional_case(Z=X[int(n/2+1):,1])
            self.funs = lambda x : (1/(R_1 - r_1))*g(x[1]) if (x[0]>=r_1) and (x[0]<=R_1) else 0 # input x : 2d np.array
            
            #return density_estimator
        


        # Condition 2
        r_2 = np.min(X[:int(n/2),1])
        R_2 = np.max(X[:int(n/2),1])

        if R_2 - r_2 < n**(1/3)*L**(-1/2):
            g = self.onedimensional_case(Z=X[int(n/2+1):,0])
            self.funs = lambda x : (1/(R_2-r_2))*g(x[0]) if (x[1]>=r_2) and (x[1]<=R_2) else 0 # input x : 2d np.array
            
            #return density_estimator
            
        

        # Condition 3 
        else:
            h_1 = math.floor((R_1-r_1)*n**(1/3)*L**(1/2))**(-1)*(R_1-r_1)
            h_2 = math.floor((R_2-r_2)*n**(1/3)*L**(1/2))**(-1)*(R_2-r_2)

            E_1 = np.arange(-math.floor(r_1/h_1),math.ceil((1-r_1)/h_1-1))
            E_2 = np.arange(-math.floor(r_2/h_2),math.ceil((1-r_2)/h_2-1))
        
            N_1 = np.zeros((len(E_1),len(E_2))) 
            N_2 = np.zeros((len(E_1),len(E_2)))
        
            for c1,i in enumerate(E_1):
                a_1 = r_1 + i*h_1
                a_2 = r_1 + (i+1)*h_1 

                for c2,j in enumerate(E_2):
                    b_1 = r_2 + j*h_2
                    b_2 = r_2 + (j+1)*h_2
        
                    N_1[c1,c2] = sum([1 if (X[k,0] >= a_1) & (X[k,0] < a_2) & (X[k,1] >= b_1) & (X[k,1] < b_2) else 0 for k in range(int(n/2)+1, int(3*n/4))])
                    N_2[c1,c2] = sum([1 if (X[k,0] >= a_1) & (X[k,0] < a_2) & (X[k,1] >= b_1) & (X[k,1] < b_2) else 0 for k in range(int(3*n/4), n)])

            P = super().fit(n=int(n/2), Y1=N_1, Y2=N_2, alpha=self.alpha, continuous_case=True)


            def f_1(x):
                s = 0
                for c1,i in enumerate(E_1):
                    for c2,j in enumerate(E_2):
                        if (x[0]>=r_1 + i*h_1) and (x[0]<r_1 + (i+1)*h_1) and (x[1]>=r_2 + j*h_2) and (x[1]<r_2 + (j+1)*h_2):
                            s += P[c1,c2]*(1/(h_1*h_2))
                return s
    
            self.funs = f_1
            
            return self
        


    def pdf(self,x_d):
        """
        Compute the estimated low-rank probability density function of a joint distribution

        Parameters 
        ---------
        x_d : np.array of shape (n_samples,2)


        Return 
        ---------
        self.funs(x_d): 
        Values of probability density function over x_d

        """
        # density estimator (python function)
        density_estimator = self.funs
        
        return list(map(density_estimator,x_d))
    



### Function to sample data to test Continuous model 
# (not function available for user of package)

# def sample_continuous_data(n_samples,K):
#     samples = []
#     beta_distrib_1 = beta(a=1,b=2)
#     beta_distrib_2 = beta(a=2,b=2)

#     for i in range(n_samples):
#         uniform = randint(low=1,high=K).rvs()
#         X = beta_distrib_1.rvs()
#         Y = beta_distrib_2.rvs()
#         samples.append([X,Y])

#     return np.array(samples)


# samples = sample_continuous_data(n_samples=10000,K=8)
# model = Continuous(alpha=0.1)
# model.fit(X=samples)
# density_funs = model.pdf(x_d=np.linspace(0,1)) # generate 

# print(density_funs)